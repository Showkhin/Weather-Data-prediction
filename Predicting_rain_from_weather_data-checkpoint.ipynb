{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Series' from 'pandas' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4e70d1e0dd7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpylab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Series' from 'pandas' (unknown location)"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "from pylab import rcParams\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing rain data\n",
    "rain1=pd.read_excel('D:\\Research_related\\Dataset\\Dataset\\Rain.xlsx',\n",
    "                 header=7)\n",
    "### dropping stati columns and here column name and index must match\n",
    "rain2=rain1.drop(['Stati'],axis=1)\n",
    "### Restracturing dataset\n",
    "rain3 = pd.melt(rain2, id_vars=[\"Year\",\"Month\"],\n",
    "             var_name='Day',value_name=\"Rain\")\n",
    "rain3.dropna(subset = [\"Rain\"], inplace=True)  ### Its drop all the nun value\n",
    "### sorting data set\n",
    "rain=rain3.sort_values(by =['Year','Month','Day'])\n",
    "rain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Importing cloud setting header row  skipping useless rows\n",
    "cloud1=pd.read_excel('D:\\Research_related\\Dataset\\Dataset\\cloud.xlsx',\n",
    "                     header=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dropping Index columns and here column name and index number must match\n",
    "cloud2=cloud1.drop(['Index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restracturing dataset\n",
    "cloud3 = pd.melt(cloud2, id_vars=[\"Year\",\"Mo\"],\n",
    "             var_name='Day',value_name=\"Cloud\")\n",
    "cloud3.dropna(subset = [\"Cloud\"], inplace=True)  ### Its drop all the nun value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sorting data set\n",
    "cloud4=cloud3.sort_values(by =['Year','Mo','Day'])\n",
    "cloud=cloud4.rename(columns={\"Mo\":\"Month\"})\n",
    "round(100*(cloud.isin(['***']).any()/len(cloud.index)),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Releted Humadity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Releted Humadity setting header row and index column and skipping useless rows\n",
    "rh1=pd.read_excel('D:\\Research_related\\Dataset\\Dataset\\RH.xlsx',\n",
    "                     header=3,skipfooter=1,usecols=range(34))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dropping Station name columns and here column name and index number must match\n",
    "rh2=rh1.drop(['Station name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restracturing dataset\n",
    "rh3 = pd.melt(rh2, id_vars=[\"Year\",\"Month\"],\n",
    "             var_name='Day',value_name=\"Releted Hum.\")\n",
    "rh3.dropna(subset = [\"Releted Hum.\"], inplace=True)  ### Its drop all the nun value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sorting data set\n",
    "rh=rh3.sort_values(by =['Year','Month','Day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sea Level Pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing Sea level pressure setting header row  skipping useless rows\n",
    "slp1=pd.read_excel('D:\\Research_related\\Dataset\\Dataset\\SLP.xlsx',\n",
    "                     header=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dropping Index columns and here column name and index number must match\n",
    "slp2=slp1.drop(['Index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restractering dataset\n",
    "slp3 = pd.melt(slp2, id_vars=[\"Year\",\"Month\"],\n",
    "             var_name='Day',value_name=\"Sea Level P.\")\n",
    "slp3.dropna(subset = [\"Sea Level P.\"], inplace=True) ### Its drop all the nun value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sorting data set\n",
    "slp=slp3.sort_values(by =['Year','Month','Day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Importing wind setting header row skipping useless rows\n",
    "wind1=pd.read_excel('D:\\Research_related\\Dataset\\Dataset\\Wind.xlsx',\n",
    "                     header=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### dropping useless columns\n",
    "wind2=wind1.drop(['DR','DR.1','DR.2','DR.3','DR.4','DR.5','DR.6','DR.7','DR.8',\n",
    "                 'DR.9','DR.10','DR.11','DR.12','DR.13','DR.14','DR.15','DR.16',\n",
    "                  'DR.17', 'DR.18','DR.19','DR.20','DR.21','DR.22','DR.23',\n",
    "                  'DR.24','DR.25','DR.26','DR.27','DR.28','DR.29','DR.30'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Renaming columns\n",
    "wind3=wind2.rename(columns={'Mon': 'Month','Sp': 1,'SP': 2,'SP.1': 3,\n",
    "                            'SP.2': 4,'SP.3': 5,'SP.4': 6,'SP.5': 7,\n",
    "                            'SP.6': 8,'SP.7': 9,'SP.8': 10,'SP.9': 11,\n",
    "                            'SP.10': 12,'SP.11': 13,'SP.12': 14,\n",
    "                            'SP.13': 15,'SP.14': 16,'SP.15': 17,\n",
    "                            'SP.16': 18,'SP.17': 19,'SP.18': 20,\n",
    "                            'SP.19': 21,'SP.20': 22,'SP.21': 23,\n",
    "                            'SP.22': 24,'SP.23': 25,'SP.24': 26,\n",
    "                            'SP.25': 27,'SP.26': 28,'SP.27': 29,\n",
    "                            'SP.28': 30,'SP.29': 31})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restractering dataset\n",
    "wind4 = pd.melt(wind3, id_vars=[\"Year\",\"Month\"],\n",
    "             var_name='Day',value_name=\"Wind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind4.dropna(subset = [\"Wind\"], inplace=True)  ### Its drop all the nun value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Sorting dataset\n",
    "wind=wind4.sort_values(by =['Year','Month'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max_Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing max temp. setting header row and index column and skipping useless rows\n",
    "maxt1=pd.read_excel('D:\\Research_related\\Dataset\\Dataset\\MaxT.xlsx',\n",
    "                     header=4,skipfooter=13,usecols=range(33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restractering dataset\n",
    "maxt2 = pd.melt(maxt1, id_vars=[\"Year\",\"Mo\"],\n",
    "             var_name='Day',value_name=\"Max_T.\")\n",
    "maxt2.dropna(subset = [\"Max_T.\"], inplace=True)  ### Its drop all the nun value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### sorting data set and changing columns name\n",
    "maxt3=maxt2.sort_values(by =['Year','Mo'])\n",
    "maxt=maxt3.rename(columns={\"Mo\":\"Month\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Min_Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing min temp. setting header row and index column and skipping useless rows\n",
    "mint1=pd.read_excel('D:\\Research_related\\Dataset\\Dataset\\MinT.xlsx',\n",
    "                     header=3,skipfooter=11,usecols=range(33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Restractering dataset\n",
    "mint2= pd.melt(mint1, id_vars=[\"Year\",\"Mo\"],\n",
    "             var_name='Day',value_name=\"Min_T.\")\n",
    "mint2.dropna(subset = [\"Min_T.\"], inplace=True)  ### Its drop all the nun value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sorting data set and changing columns name\n",
    "mint3=mint2.sort_values(by =['Year','Mo'])\n",
    "mint=mint3.rename(columns={\"Mo\":\"Month\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mergeing all data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1=pd.merge(rain,maxt)\n",
    "df2=pd.merge(df1,mint)\n",
    "df3=pd.merge(df2,cloud)\n",
    "df4=pd.merge(df3,rh)\n",
    "df5=pd.merge(df4,slp)\n",
    "df6=pd.merge(df5,wind)\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7=df6.replace(to_replace=\"***\", method='ffill') ###it fill all \"***\" values with ffill\n",
    "df8=df7.replace(to_replace=\"****\", method='ffill')\n",
    "df9=df8.replace(to_replace=\"*****\", method='ffill')\n",
    "df=df9.replace(to_replace=\"******\", method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=df.sort_values(by =['Month','Day','Year'])\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "date=df.apply(lambda x: datetime.date(int(x['Year']), x['Month'], x['Day']),axis=1)\n",
    "date = pd.to_datetime(date)\n",
    "dfm = df.drop(columns=['Day'])\n",
    "dfm.insert(0, 'Date', date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfm=dfm.set_index('Date')\n",
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Max_T.','Min_T.','Cloud','Sea Level P.','Wind']\n",
    "dfm[cols] = dfm[cols].apply(pd.to_numeric, errors='coerce', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(14,4)})\n",
    "## Use seaborn style defaults and set the default figure size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm['Rain'].plot(linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm['Wind'].plot(linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_plot = ['Max_T.','Min_T.']\n",
    "axes = dfm[cols_plot].plot(marker='.',alpha=0.5,linestyle='None',\n",
    "                           figsize=(11,9),subplots=True)\n",
    "for ax in axes:\n",
    "    ax.set_title('From 1988 to 2017')\n",
    "    ax.set_ylabel('Daily Tempareture rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = dfm.loc['2010', 'Rain'].plot()\n",
    "ax.set_title('2010 Rainfall rate')\n",
    "ax.set_ylabel('Daily Rainfall rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = dfm.loc['2010-06':'2010-07', 'Wind'].plot(marker ='o',linestyle='-')\n",
    "ax.set_title('June-July 2010 Wind')\n",
    "ax.set_ylabel('Daily Wind rate');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "ax.plot(dfm.loc['2010-06':'2010-07', 'Rain'],marker ='o',linestyle='-')\n",
    "ax.set_ylabel('Daily Rainfall rate')\n",
    "ax.set_title('June-July 2010 Rainfall rate')\n",
    "\n",
    "ax.xaxis.set_major_locator(mdates.WeekdayLocator(byweekday=mdates.SUNDAY))\n",
    "\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,1, figsize= (11,15),sharex=True)\n",
    "for name, ax in zip(['Cloud','Sea Level P.','Releted Hum.','Wind'],axes):\n",
    "    sns.boxplot(data=dfm, x='Month', y=name, ax=ax)\n",
    "ax.set_ylabel('')\n",
    "ax.set_title(name)\n",
    "# Remove the automatic x-axis label from all but the bottm subplot\n",
    "if ax != axes[-1]:\n",
    "    ax.set_xlabel('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These box plots confirm that\n",
    "1.There are less cloud in winter and much cloud in summer\n",
    "2.The Sea Level P. rises high in winter and lows in summer\n",
    "3.Releted Hum. stays average in winter and rises in summer\n",
    "4.Wind stays average through out the year though rises in summer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_columns = ['Rain' ,'Max_T.','Min_T.','Cloud','Releted Hum.','Sea Level P.','Wind']\n",
    "dfm_weekly_mean = dfm[data_columns].resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Start and end of the date range to extract\n",
    "start, end ='2010-03','2010-10'\n",
    "#Plot daily and weekly resampled time series together\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(dfm.loc[start:end,'Min_T.'],marker='.',linestyle='-',label='Daily')\n",
    "ax.plot(dfm_weekly_mean.loc[start:end,'Min_T.'],marker='o',markersize=8,\n",
    "       linestyle='-',label='Weekly mean resample')\n",
    "ax.set_ylabel('Min temperature rate')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shows the daily and weekly resampled rainfall for '2010-03','2010-10' time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the monthly sums\n",
    "dfm_monthly = dfm[data_columns].resample('M').sum(min_count=28)\n",
    "dfm_monthly.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(dfm_monthly['Wind'], color='black', label='Wind')\n",
    "dfm_monthly[['Max_T.', 'Min_T.']].plot.area(ax=ax, linewidth=0)\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.legend()\n",
    "ax.set_ylabel('Monthly Total');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see that Max Tem. ,Min tem. and wind fairly stable over time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Making sure cloud is a binary variable \n",
    "sns.countplot(x='Cloud',data=dfm,palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Max_T.',data=dfm,palette='hls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfm.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(100*(df.isnull().sum()/len(df.index)),2) #This shows the percentage of missing value per column and per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reseting indexing\n",
    "dfm.reset_index(drop=True,inplace=True)\n",
    "dfm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THE dataframe don't have any missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dropping usless columns\n",
    "data=dfm.drop(['Year','Month'],1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"Wind\"].fillna( method ='ffill', limit = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt \n",
    "import sys\n",
    "from scipy.stats import randint\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "## Deep-learing:\n",
    "\n",
    "from keras.optimizers import SGD \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "import itertools\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from __future__ import print_function\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras import backend as k\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split into train and test sets\n",
    "X=data.iloc[:,1:7]\n",
    "y=data.iloc[:,0]\n",
    "### split into input and outputs\n",
    "train_X,test_X,train_y,test_y = train_test_split(X,y,test_size = .3, random_state=25)\n",
    "### reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.values.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.values.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) \n",
    "### We reshaped the input into the 3D format as expected by LSTMs, namely [samples, timesteps, features]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(100, return_sequences=True, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "### fit network\n",
    "history = model.fit(train_X, train_y, epochs=10, batch_size=20, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "### summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a prediction\n",
    "yhat = model.predict(test_X, verbose=0)\n",
    "rmse = np.sqrt(mean_squared_error(test_y, yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM gave RMSE for rain is :13.366"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,1:7] \n",
    "y=data.iloc[:,0]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = .3, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training a KNN classifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn = KNeighborsClassifier(n_neighbors = 7).fit(X_train, y_train) \n",
    "### for k or n_neighbors=5 accuracy 0.3515****\n",
    "### accuracy on X_test \n",
    "accuracy = knn.score(X_test, y_test) \n",
    "### creating a confusion matrix \n",
    "knn_predictions = knn.predict(X_test)  \n",
    "cm = confusion_matrix(y_test, knn_predictions) \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, knn_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN gave accuracy for rain :0.6602798053527981"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training a DescisionTreeClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "dtree_model = DecisionTreeClassifier(max_depth = 2).fit(X_train, y_train) \n",
    "dtree_predictions = dtree_model.predict(X_test) \n",
    "### creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, dtree_predictions) \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, dtree_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree gave accuracy for rain: 0.6730535279805353"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier \n",
    "from sklearn.svm import SVC \n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train) \n",
    "svm_predictions = svm_model_linear.predict(X_test) \n",
    "# model accuracy for X_test   \n",
    "accuracy = svm_model_linear.score(X_test, y_test) \n",
    "\n",
    "# creating a confusion matrix \n",
    "cm = confusion_matrix(y_test, svm_predictions) \n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM gave accuracy for rain:0.6727493917274939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(),center=0,cmap='coolwarm',annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogReg = LogisticRegression(max_iter=10958 ,multi_class='multinomial')\n",
    "LogReg.fit(X_train,y_train)\n",
    "y_pred = LogReg.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(classification_report(y_test, y_pred ,labels=np.unique(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regration gave accuracy for rain:0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
